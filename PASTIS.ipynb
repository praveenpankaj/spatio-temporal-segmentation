{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveenpankaj/spatio-temporal-segmentation/blob/main/PASTIS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <a href=\"https://colab.research.google.com/github/praveenpankaj/spatio-temporal-segmentation/blob/main/PASTIS.ipynb\" target=\"_parent\">\n",
        "# <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "# </a>"
      ],
      "metadata": {
        "id": "Qsj4Ho3mOqkY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âš™ï¸ Installing Required Dependencies"
      ],
      "metadata": {
        "id": "27rKOX8jcW_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Move this to requirements.txt\n",
        "print(\"âš™ï¸ Installing dependencies...\")\n",
        "!pip install torchnet\n",
        "!pip install torch_scatter"
      ],
      "metadata": {
        "id": "gszoVTgNcUxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“¥ Downloading PASTIS Data"
      ],
      "metadata": {
        "id": "NZX9mJp5e8Jn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNQ97ubFvsdj",
        "outputId": "a7df1030-015c-430b-8383-9f2e8022f6e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-23 15:31:28--  https://zenodo.org/records/5012942/files/PASTIS.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.45.92, 188.185.48.194, 188.185.43.25, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.45.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28760245504 (27G) [application/octet-stream]\n",
            "Saving to: â€˜PASTIS.zipâ€™\n",
            "\n",
            "PASTIS.zip           59%[==========>         ]  16.06G  14.4MB/s    eta 13m 1s "
          ]
        }
      ],
      "source": [
        "# Uncomment the following line to download the dataset if it's not already present\n",
        "!wget https://zenodo.org/records/5012942/files/PASTIS.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzipping the dataset\n",
        "print(\"ðŸ“‚ Extracting PASTIS dataset...\")\n",
        "!unzip -q PASTIS.zip\n"
      ],
      "metadata": {
        "id": "3cIaTmXj0YYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment this line to remove the downloaded archive file\n",
        "# rm -r '/content/PASTIS.zip'"
      ],
      "metadata": {
        "id": "zVvC6IwHDZHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ”— Mounting Google Drive in Colab"
      ],
      "metadata": {
        "id": "_KbdNGkefVLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "if not os.path.exists('outpath'):\n",
        "  os.mkdir('outpath')"
      ],
      "metadata": {
        "id": "ozgBBn6fCNmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access and store data\n",
        "print(\"ðŸ”— Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57SHgF0nxNTq",
        "outputId": "ccfa73e0-e32c-4fe8-d5b6-ba30e41607dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸšš Transferring PASTIS data from Google Colab to Google Drive"
      ],
      "metadata": {
        "id": "WzHk_2B9fh_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define source and destination paths\n",
        "src_path = '/content/outpath'\n",
        "dst_path = '/content/drive/MyDrive/PASTIS_Data/'\n",
        "\n",
        "# Move dataset from Colab storage to Google Drive\n",
        "print(f\"ðŸš› Moving dataset to Google Drive: {dst_path}\")\n",
        "shutil.move(src_path, dst_path)\n",
        "print(\"âœ… File moved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSJXaQXrxYWt",
        "outputId": "9afa43d6-c6a1-44e2-df5f-ea65968b2fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File moved to: /content/drive/MyDrive/PASTIS_Data/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“Š Sampling 100 Data Points from Each Region\n",
        "\n",
        "Also need to change Tile names in metadata.geojson file to sample"
      ],
      "metadata": {
        "id": "_Msc-gnpgNEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the metadata file\n",
        "geojson_file = '/content/drive/MyDrive/PASTIS_Data/metadata.geojson'\n",
        "\n",
        "# List to store selected patch IDs\n",
        "file_list = []\n",
        "\n",
        "try:\n",
        "    with open(geojson_file, 'r') as file:\n",
        "        geojson_data = json.load(file)\n",
        "\n",
        "    count = 0\n",
        "    target_tile = \"roi_pallab_200\"  # Change as needed: \"roi_pallab_100\", \"roi_pallab_200\", \"roi_pallab_300\"\n",
        "\n",
        "    for feature in geojson_data['features']:\n",
        "        if 'TILE' in feature['properties']:\n",
        "            if feature['properties']['TILE'] == target_tile:\n",
        "                count += 1\n",
        "                if count <= 100:\n",
        "                    file_list.append(feature['properties']['ID_PATCH'])\n",
        "\n",
        "    print(f\"âœ… Sampled {len(file_list)} patches from {target_tile}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error processing GeoJSON file: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JpP-FF9x5aM",
        "outputId": "ebdcb03d-c3a2-4749-f760-050122d4a8f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File List: [10101, 10102, 10103, 10104, 10105, 10106, 10107, 10108, 10109, 10110, 10111, 10112, 10113, 10114, 10115, 10116, 10117, 10118, 10119, 10120, 10121, 10122, 10123, 10124, 10125, 10126, 10127, 10128, 10129, 10130, 10131, 10132, 10133, 10134, 10135, 10136, 10137, 10138, 10139, 10140, 10141, 10142, 10143, 10144, 10145, 10146, 10147, 10148, 10149, 10150, 10151, 10152, 10153, 10154, 10155, 10156, 10157, 10158, 10159, 10160, 10161, 10162, 10163, 10164, 10165, 10166, 10167, 10168, 10169, 10170, 10171, 10172, 10173, 10174, 10175, 10176, 10177, 10178, 10179, 10180, 10181, 10182, 10183, 10184, 10185, 10186, 10187, 10188, 10189, 10190, 10191, 10192, 10193, 10194, 10195, 10196, 10197, 10198, 10199, 10200]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ðŸŽ›ï¸ Noise Implementation - Adding Noise to 25% of Training Data"
      ],
      "metadata": {
        "id": "i36YlKSpeHrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to add Gaussian noise to image data\n",
        "def add_gaussian_noise(data, mean=0, std=25):\n",
        "    \"\"\"Applies Gaussian noise to an image.\"\"\"\n",
        "    gauss = np.random.normal(mean, std, data.shape).astype('float32')\n",
        "    return data + gauss\n",
        "\n",
        "# Define directory containing the dataset\n",
        "input_dir = '/content/drive/MyDrive/PASTIS_Data/DATA_S2'\n",
        "\n",
        "\n",
        "# Define start and end indices for applying noise\n",
        "start_idx = 10101\n",
        "end_idx = 10200\n",
        "\n",
        "print(\"ðŸ–¼ï¸ Applying Gaussian noise to selected images...\")\n",
        "\n",
        "\n",
        "# Iterate through dataset and apply noise to selected files\n",
        "for filename in os.listdir(input_dir):\n",
        "    if filename.endswith('.npy'):\n",
        "        idx = int(filename.split('_')[1].split('.')[0])\n",
        "        input_path = os.path.join(input_dir, filename)\n",
        "\n",
        "        if os.path.isfile(input_path) and start_idx <= idx <= end_idx:\n",
        "            data = np.load(input_path)\n",
        "            noisy_data = add_gaussian_noise(data)\n",
        "            np.save(input_path, noisy_data)\n",
        "            print(f\"ðŸŽ¨ Processed with noise: {input_path}\")\n",
        "        else:\n",
        "            print(f\"âš ï¸ Skipping: {input_path} (Outside range or missing)\")"
      ],
      "metadata": {
        "id": "4hRdoZf1y4dR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ› ï¸ Cloning Required GitHub Repositories"
      ],
      "metadata": {
        "id": "-e2vwbYGlMZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ðŸ“¥ Cloning required repositories...\")\n",
        "!git clone https://github.com/VSainteuf/utae-paps.git"
      ],
      "metadata": {
        "id": "LhlcxJoI1Awd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/VSainteuf/pastis-benchmark.git"
      ],
      "metadata": {
        "id": "hDg5aUPICKJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“‚ Verifying Dataset Files in Drive"
      ],
      "metadata": {
        "id": "VDlSRDv-b-8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data directory\n",
        "data_dir = '/content/drive/MyDrive/PASTIS_Data'\n",
        "\n",
        "# List all files in the directory\n",
        "files = os.listdir(data_dir)\n",
        "\n",
        "# Print the file names\n",
        "print(\"ðŸ“‚ Files in dataset directory:\", files)\n",
        "#['NORM_S2_patch.json', 'ANNOTATIONS', 'DATA_S2', 'INSTANCE_ANNOTATIONS', 'metadata.geojson', '.ipynb_checkpoints']"
      ],
      "metadata": {
        "id": "yBVoJSQ9KW5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ‹ï¸ Training and Inference"
      ],
      "metadata": {
        "id": "ciPQUTcblkJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ðŸš€ Training segmentation model...\")\n",
        "!python train_semantic.py --fold 1 --dataset_folder $data_dir --res_dir '/content/outpath'\n",
        "\n",
        "print(\"âœ… Training complete! Results saved to '/content/outpath'\")"
      ],
      "metadata": {
        "id": "CNgH9qJiF56V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}